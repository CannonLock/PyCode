import c
import torch
from music21 import converter, instrument, note, chord, stream


def generate_song(model, start_note, length):
	song = torch.tensor(start_note).view(1)

	for i in length:
		logits = model(song)
		_, predicted_labels = torch.max(logits, 1)
		song = torch.cat(song, predicted_labels[-1])

	return song

def ints_to_notes(song, int_to_str):
	return [int_to_str[x] for x in song]

def create_midi(prediction):
	offset = 0
	output_notes = []

	# create note and chord objects based on the values generated by the model
	for pattern in prediction:
		if pattern == "rest":
			new_note = note.Rest()
			new_note.offset = offset
			output_notes.append(new_note)
		# pattern is a chord
		elif ' ' in pattern:
			new_chord = chord.Chord(pattern)
			new_chord.offset = offset
			output_notes.append(new_chord)
		# pattern is a note
		else:
			new_note = note.Note(pattern)
			new_note.offset = offset
			new_note.storedInstrument = instrument.Piano()
			output_notes.append(new_note)

		# increase offset each iteration so that notes do not stack
		offset += 0.5

	midi_stream = stream.Stream(output_notes)

	midi_stream.write('midi', fp='test_output.mid')


