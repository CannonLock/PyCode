import c
import torch
from music21 import converter, instrument, note, chord, stream


def generate_song(model, start_note, length):
	song = torch.tensor(start_note).view(1)

	for i in range(length):
		logits = model(song)
		probas = torch.softmax(logits,dim = 0)
		predicted_labels = torch.multinomial(probas,1)
		song = torch.cat((song.view(-1), predicted_labels[-1].view(-1)))

	return song

def ints_to_notes(song, int_to_str):
	return [int_to_str[x] for x in song]

def create_midi(prediction, file_path):
	offset = 0
	output_notes = []

	# create note and chord objects based on the values generated by the model
	for pattern in prediction:
		if pattern == "rest":
			new_note = note.Rest()
			new_note.offset = offset
			output_notes.append(new_note)
		# pattern is a chord
		elif ' ' in pattern:
			notes_in_chord = pattern.split(' ')
			notes = []
			for current_note in notes_in_chord:
				new_note = note.Note(current_note)
				new_note.storedInstrument = instrument.BassDrum()
				notes.append(new_note)
			new_chord = chord.Chord(notes)
			new_chord.offset = offset
			output_notes.append(new_chord)
		# pattern is a note
		else:
			new_note = note.Note(pattern)
			new_note.offset = offset
			new_note.storedInstrument = instrument.BassDrum()
			output_notes.append(new_note)

		# increase offset each iteration so that notes do not stack
		offset += 0.5

	midi_stream = stream.Stream(output_notes)

	midi_stream.write('midi', fp=file_path)


